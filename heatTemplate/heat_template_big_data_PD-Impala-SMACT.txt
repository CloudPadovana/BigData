heat_template_version: 2013-05-23
description: Create VM, network and security group for Big Data testing 

parameters:
    
  image_centos_7:
    type: string
    label: Image name or ID
    description: Image used for all nodo in big data cluster (CentOS7)
    default: fb2906c4-56a1-45a1-9041-485716cb7016
  
  flavor_to_use:
    type: string
    label: Flavor name 
    description: Flavor used for all nodes in the cluster
    default: cldareapd.small

  key_name_user:
   type: string
   label: Public ssh key of one user.
   description: Public ssh key of one user.
   default: mbuto-desktop

  tenant_net_id:
    type: string
    label: Network ID of the tenant
    description: This parameter has been set with the id of the tenant network
    default: d68e615a-7716-4e95-a413-492339300b58

  tenant_subnet_name:
    type: string
    label: Sub network of the tenant
    description: This parameter has been set with the name of the tenant sub network.
    default: "sub-SMACT-lan"

  net_domain:
    type: string
    label: Sub-domain for the cluster installation
    description: Sub-domain for the cluster installation.
    default: "smact"

  net_host_prefix:
    type: string
    label: Prefix for the hostname of the cluster nodes
    description: Prefix for the hostname of the cluster nodes.
    default: "impala-test"

  fixed_ip_node_1:
    type: string
    label: Fixed ip for node1 host
    description: Fixed ip for node1 host
    default: "10.64.48.50"

  fixed_ip_node_2:
    type: string
    label: Fixed ip for node2 host
    description: Fixed ip for node2 host
    default: "10.64.48.51"

  fixed_ip_node_3:
    type: string
    label: Fixed ip for node3 host
    description: Fixed ip for node3 host
    default: "10.64.48.52"

  nameserver_1:
    type: string
    label: First name server ip
    description: First name server ip
    default: "192.84.143.31"

  nameserver_2:
    type: string
    label: Second name server ip
    description: Second name server ip
    default: "192.84.143.16"

  hadoop_ver:
    type: string
    label: Hadoop version
    description: Hadoop version
    default: "2.9.1"

resources:
  
  root_pw:
   type: OS::Heat::RandomString
   properties:
      length: 8 

  hadoop_pw:
   type: OS::Heat::RandomString
   properties:
      length: 8


  secgroup-impala_sg:
    type: OS::Neutron::SecurityGroup
    properties:
      description: "Access to ssh, ping, mesos, marathon, chronos connections for all VM in this security group"
      name: "sshPingBigdata"
      rules: [
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 22, "remote_mode": remote_ip_prefix, "port_range_max": 22, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 5050, "remote_mode": remote_ip_prefix, "port_range_max": 5050, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 8080, "remote_mode": remote_ip_prefix, "port_range_max": 8080, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 4400, "remote_mode": remote_ip_prefix, "port_range_max": 4400, "protocol": TCP}, 
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 2181, "remote_mode": remote_ip_prefix, "port_range_max": 2181, "protocol": TCP}, 
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 2888, "remote_mode": remote_ip_prefix, "port_range_max": 2888, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 3888, "remote_mode": remote_ip_prefix, "port_range_max": 3888, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "port_range_min": 9000, "remote_mode": remote_ip_prefix, "port_range_max": 9000, "protocol": TCP},
        {"direction": ingress, "remote_ip_prefix": 0.0.0.0/0, "remote_mode": remote_ip_prefix, "protocol": ICMP}
      ]


  pnode1_server_port:
    type: OS::Neutron::Port
    properties:
      name: "pnode1-server-port"
      network_id: { get_param: tenant_net_id }
      fixed_ips:
        - { ip_address: { get_param: fixed_ip_node_1 }, subnet: { get_param: tenant_subnet_name } }
      security_groups: [{Ref: secgroup-impala_sg},]

  node1_server_instance:
    type: OS::Nova::Server
    properties:
      name: 
        str_replace:
            template: "$HOST_PRE-01"
            params:
                $HOST_PRE: { get_param: net_host_prefix }
      key_name: { get_param: key_name_user }
      image: { get_param: image_centos_7 } 
      flavor: { get_param: flavor_to_use }
      admin_pass: { get_resource: root_pw }
      networks:
        - port: { get_resource: pnode1_server_port }
      user_data_format: RAW
      user_data:
        str_replace:
          template: |
            #!/bin/bash
            hostnamectl set-hostname $HOST_PRE-01.$S_DOMAIN.pd.infn.it
            cat > /etc/hosts << EOF
            127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
            ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
            $IP_FIX_NODE1    $HOST_PRE-01.$S_DOMAIN.pd.infn.it    $HOST_PRE-01
            $IP_FIX_NODE2    $HOST_PRE-02.$S_DOMAIN.pd.infn.it    $HOST_PRE-02
            $IP_FIX_NODE3    $HOST_PRE-03.$S_DOMAIN.pd.infn.it    $HOST_PRE-03
            EOF
            cat > /etc/resolv.conf << EOF
            search smact.pd.infn.it pd.infn.it
            nameserver $IP_NS1 $IP_NS2
            EOF
            cat > /etc/ssh/shosts.equiv << EOF
            $HOST_PRE-01.$S_DOMAIN.pd.infn.it
            $HOST_PRE-02.$S_DOMAIN.pd.infn.it
            $HOST_PRE-03.$S_DOMAIN.pd.infn.it
            EOF
            cat >> /etc/ssh/sshd_config << EOF
            # workaround
            HostbasedAuthentication yes
            IgnoreUserKnownHosts yes
            IgnoreRhosts yes
            EOF
            cat > /etc/ssh/ssh_config << EOF
            Host *
                HostbasedAuthentication yes
                EnableSSHKeysign yes
                GSSAPIAuthentication no
                ForwardX11Trusted yes
                SendEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES
                SendEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT
                SendEnv LC_IDENTIFICATION LC_ALL LANGUAGE
                SendEnv XMODIFIERS
            EOF
            yum localinstall -y http://archive.cloudera.com/cdh5/one-click-install/redhat/7/x86_64/cloudera-cdh-5-0.x86_64.rpm
            yum install -y ntp tar wget git telnet epel-release sshpass java-1.8.0-openjdk.x86_64 zookeeper-server
            sed -i 0,/'requiretty'/{s/'requiretty'/'!requiretty'/} /etc/sudoers
            sudo -u zookeeper /bin/zookeeper-server-initialize --myid=$HOST_NUMBER
            cat >> /etc/zookeeper/conf/zoo.cfg << EOF
            server.1=$HOST_PRE-01.$S_DOMAIN.pd.infn.it:2888:3888
            server.2=$HOST_PRE-02.$S_DOMAIN.pd.infn.it:2888:3888
            server.3=$HOST_PRE-03.$S_DOMAIN.pd.infn.it:2888:3888
            EOF
            systemctl enable zookeeper-server
            cat >> /etc/bashrc << EOF
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export JRE_HOME=/usr/lib/jvm/jre-1.8.0-openjdk/jre
            EOF
            cat >> /etc/sysctl.conf << EOF
            net.ipv6.conf.all.disable_ipv6 = 1
            net.ipv6.conf.default.disable_ipv6 = 1
            EOF
            chmod 777 /opt/
            useradd hadoop
            echo -n hadoop:$HADOOP_PW | chpasswd
            source /etc/bashrc
            wget -O /tmp/hadoop-$HDOOP_V.tar.gz http://www.eu.apache.org/dist/hadoop/common/hadoop-$HDOOP_V/hadoop-$HDOOP_V.tar.gz
            tar -C /opt -zxf /tmp/hadoop-$HDOOP_V.tar.gz
            mv /opt/hadoop-$HDOOP_V /opt/hadoop
            chown -R hadoop.hadoop /opt/hadoop
            cat >> /home/hadoop/.bashrc << EOF
            export HADOOP_PREFIX=/opt/hadoop
            export HADOOP_HOME=\$HADOOP_PREFIX
            export HADOOP_COMMON_HOME=\$HADOOP_PREFIX
            export HADOOP_CONF_DIR=\$HADOOP_PREFIX/etc/hadoop
            export HADOOP_HDFS_HOME=\$HADOOP_PREFIX
            export HADOOP_MAPRED_HOME=\$HADOOP_PREFIX
            export HADOOP_YARN_HOME=\$HADOOP_PREFIX
            export PATH=\$PATH:\$HADOOP_PREFIX/sbin:\$HADOOP_PREFIX/bin
            EOF
            #
            # https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/
            #
            mkdir /home/hadoop/datanode /home/hadoop/namenode
            chown hadoop.hadoop /home/hadoop/datanode /home/hadoop/namenode
            cat > /opt/hadoop/etc/hadoop/core-site.xml << EOF
            <configuration>
              <property>
                <name>fs.defaultFS</name>
                <value>hdfs://$HOST_PRE-01.$S_DOMAIN.pd.infn.it:9000/</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/hdfs-site.xml << EOF
            <configuration>
              <property>
                <name>dfs.replication</name>
                <value>1</value>
              </property>
              <property>
                <name>dfs.permissions</name>
                <value>false</value>
              </property>
              <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/hadoop/datanode</value>
              </property>
              <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/hadoop/namenode</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/mapred-site.xml << EOF
            <configuration>
              <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/yarn-site.xml << EOF
            <configuration>
              <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/slaves << EOF
            $HOST_PRE-02
            $HOST_PRE-03
            EOF
          params:
            $IP_FIX_NODE1: { get_param: fixed_ip_node_1 }
            $IP_FIX_NODE2: { get_param: fixed_ip_node_2 }
            $IP_FIX_NODE3: { get_param: fixed_ip_node_3 }
            $IP_NS1: { get_param: nameserver_1 }
            $IP_NS2: { get_param: nameserver_2 }
            $HOST_NUMBER: "1"
            $ROOT_PW: {get_resource: root_pw}
            $HADOOP_PW: {get_resource: hadoop_pw}
            $HOST_PRE: { get_param: net_host_prefix }
            $S_DOMAIN: { get_param: net_domain }
            $HDOOP_V: { get_param: hadoop_ver }





  pnode2_server_port:
    type: OS::Neutron::Port
    properties:
      name: "pnode2-server-port"
      network_id: { get_param: tenant_net_id }
      fixed_ips:
        - { ip_address: { get_param: fixed_ip_node_2 }, subnet: { get_param: tenant_subnet_name } }
      security_groups: [{Ref: secgroup-impala_sg},]

  node2_server_instance:
    type: OS::Nova::Server
    properties:
      name: 
        str_replace:
            template: "$HOST_PRE-02"
            params:
                $HOST_PRE: { get_param: net_host_prefix }
      key_name: { get_param: key_name_user }
      image: { get_param: image_centos_7 } 
      flavor: { get_param: flavor_to_use }
      admin_pass: { get_resource: root_pw }
      networks:
        - port: { get_resource: pnode2_server_port }
      user_data_format: RAW
      user_data:
        str_replace:
          template: |
            #!/bin/bash
            hostnamectl set-hostname $HOST_PRE-02.$S_DOMAIN.pd.infn.it
            cat > /etc/hosts << EOF
            127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
            ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
            $IP_FIX_NODE1    $HOST_PRE-01.$S_DOMAIN.pd.infn.it    $HOST_PRE-01
            $IP_FIX_NODE2    $HOST_PRE-02.$S_DOMAIN.pd.infn.it    $HOST_PRE-02
            $IP_FIX_NODE3    $HOST_PRE-03.$S_DOMAIN.pd.infn.it    $HOST_PRE-03
            EOF
            cat > /etc/resolv.conf << EOF
            search smact.pd.infn.it pd.infn.it
            nameserver $IP_NS1 $IP_NS2
            EOF
            cat > /etc/ssh/shosts.equiv << EOF
            $HOST_PRE-01.$S_DOMAIN.pd.infn.it
            $HOST_PRE-02.$S_DOMAIN.pd.infn.it
            $HOST_PRE-03.$S_DOMAIN.pd.infn.it
            EOF
            cat >> /etc/ssh/sshd_config << EOF
            # workaround
            HostbasedAuthentication yes
            IgnoreUserKnownHosts yes
            IgnoreRhosts yes
            EOF
            cat > /etc/ssh/ssh_config << EOF
            Host *
                HostbasedAuthentication yes
                EnableSSHKeysign yes
                GSSAPIAuthentication no
                ForwardX11Trusted yes
                SendEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES
                SendEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT
                SendEnv LC_IDENTIFICATION LC_ALL LANGUAGE
                SendEnv XMODIFIERS
            EOF
            yum localinstall -y http://archive.cloudera.com/cdh5/one-click-install/redhat/7/x86_64/cloudera-cdh-5-0.x86_64.rpm
            yum install -y ntp tar wget git telnet epel-release sshpass java-1.8.0-openjdk.x86_64 zookeeper-server
            sed -i 0,/'requiretty'/{s/'requiretty'/'!requiretty'/} /etc/sudoers
            sudo -u zookeeper /bin/zookeeper-server-initialize --myid=$HOST_NUMBER
            cat >> /etc/zookeeper/conf/zoo.cfg << EOF
            server.1=$HOST_PRE-01.$S_DOMAIN.pd.infn.it:2888:3888
            server.2=$HOST_PRE-02.$S_DOMAIN.pd.infn.it:2888:3888
            server.3=$HOST_PRE-03.$S_DOMAIN.pd.infn.it:2888:3888
            EOF
            systemctl enable zookeeper-server
            cat >> /etc/bashrc << EOF
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export JRE_HOME=/usr/lib/jvm/jre-1.8.0-openjdk/jre
            EOF
            cat >> /etc/sysctl.conf << EOF
            net.ipv6.conf.all.disable_ipv6 = 1
            net.ipv6.conf.default.disable_ipv6 = 1
            EOF
            chmod 777 /opt/
            useradd hadoop
            echo -n hadoop:$HADOOP_PW | chpasswd
            source /etc/bashrc
            wget -O /tmp/hadoop-$HDOOP_V.tar.gz http://www.eu.apache.org/dist/hadoop/common/hadoop-$HDOOP_V/hadoop-$HDOOP_V.tar.gz
            tar -C /opt -zxf /tmp/hadoop-$HDOOP_V.tar.gz
            mv /opt/hadoop-$HDOOP_V /opt/hadoop
            chown -R hadoop.hadoop /opt/hadoop
            cat >> /home/hadoop/.bashrc << EOF
            export HADOOP_PREFIX=/opt/hadoop
            export HADOOP_HOME=\$HADOOP_PREFIX
            export HADOOP_COMMON_HOME=\$HADOOP_PREFIX
            export HADOOP_CONF_DIR=\$HADOOP_PREFIX/etc/hadoop
            export HADOOP_HDFS_HOME=\$HADOOP_PREFIX
            export HADOOP_MAPRED_HOME=\$HADOOP_PREFIX
            export HADOOP_YARN_HOME=\$HADOOP_PREFIX
            export PATH=$PATH:\$HADOOP_PREFIX/sbin:\$HADOOP_PREFIX/bin
            EOF
            #
            # https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/
            #
            mkdir /home/hadoop/datanode /home/hadoop/namenode
            chown hadoop.hadoop /home/hadoop/datanode /home/hadoop/namenode
            cat > /opt/hadoop/etc/hadoop/core-site.xml << EOF
            <configuration>
              <property>
                <name>fs.defaultFS</name>
                <value>hdfs://$HOST_PRE-01.$S_DOMAIN.pd.infn.it:9000/</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/hdfs-site.xml << EOF
            <configuration>
              <property>
                <name>dfs.replication</name>
                <value>1</value>
              </property>
              <property>
                <name>dfs.permissions</name>
                <value>false</value>
              </property>
              <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/hadoop/datanode</value>
              </property>
              <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/hadoop/namenode</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/mapred-site.xml << EOF
            <configuration>
              <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/yarn-site.xml << EOF
            <configuration>
              <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/slaves << EOF
            $HOST_PRE-02
            $HOST_PRE-03
            EOF
          params:
            $IP_FIX_NODE1: { get_param: fixed_ip_node_1 }
            $IP_FIX_NODE2: { get_param: fixed_ip_node_2 }
            $IP_FIX_NODE3: { get_param: fixed_ip_node_3 }
            $IP_NS1: { get_param: nameserver_1 }
            $IP_NS2: { get_param: nameserver_2 }
            $HOST_NUMBER: "2"
            $ROOT_PW: {get_resource: root_pw}
            $HADOOP_PW: {get_resource: hadoop_pw}
            $HOST_PRE: { get_param: net_host_prefix }
            $S_DOMAIN: { get_param: net_domain }
            $HDOOP_V: { get_param: hadoop_ver }



  pnode3_server_port:
    type: OS::Neutron::Port
    properties:
      name: "pnode3-server-port"
      network_id: { get_param: tenant_net_id }
      fixed_ips:
        - { ip_address: { get_param: fixed_ip_node_3 }, subnet: { get_param: tenant_subnet_name } }
      security_groups: [{Ref: secgroup-impala_sg},]

  node3_server_instance:
    type: OS::Nova::Server
    properties:
      name: 
        str_replace:
            template: "$HOST_PRE-03"
            params:
                $HOST_PRE: { get_param: net_host_prefix }
      key_name: { get_param: key_name_user }
      image: { get_param: image_centos_7 } 
      flavor: { get_param: flavor_to_use }
      admin_pass: { get_resource: root_pw }
      networks:
        - port: { get_resource: pnode3_server_port }
      user_data_format: RAW
      user_data:
        str_replace:
          template: |
            #!/bin/bash
            hostnamectl set-hostname $HOST_PRE-03.$S_DOMAIN.pd.infn.it
            cat > /etc/hosts << EOF
            127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
            ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
            $IP_FIX_NODE1    $HOST_PRE-01.$S_DOMAIN.pd.infn.it    $HOST_PRE-01
            $IP_FIX_NODE2    $HOST_PRE-02.$S_DOMAIN.pd.infn.it    $HOST_PRE-02
            $IP_FIX_NODE3    $HOST_PRE-03.$S_DOMAIN.pd.infn.it    $HOST_PRE-03
            EOF
            cat > /etc/resolv.conf << EOF
            search smact.pd.infn.it pd.infn.it
            nameserver $IP_NS1 $IP_NS2
            EOF
            cat > /etc/ssh/shosts.equiv << EOF
            $HOST_PRE-01.$S_DOMAIN.pd.infn.it
            $HOST_PRE-02.$S_DOMAIN.pd.infn.it
            $HOST_PRE-03.$S_DOMAIN.pd.infn.it
            EOF
            cat >> /etc/ssh/sshd_config << EOF
            # workaround
            HostbasedAuthentication yes
            IgnoreUserKnownHosts yes
            IgnoreRhosts yes
            EOF
            cat > /etc/ssh/ssh_config << EOF
            Host *
                HostbasedAuthentication yes
                EnableSSHKeysign yes
                GSSAPIAuthentication no
                ForwardX11Trusted yes
                SendEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES
                SendEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT
                SendEnv LC_IDENTIFICATION LC_ALL LANGUAGE
                SendEnv XMODIFIERS
            EOF
            yum localinstall -y http://archive.cloudera.com/cdh5/one-click-install/redhat/7/x86_64/cloudera-cdh-5-0.x86_64.rpm
            yum install -y ntp tar wget git telnet epel-release sshpass java-1.8.0-openjdk.x86_64 zookeeper-server
            sed -i 0,/'requiretty'/{s/'requiretty'/'!requiretty'/} /etc/sudoers
            sudo -u zookeeper /bin/zookeeper-server-initialize --myid=$HOST_NUMBER
            cat >> /etc/zookeeper/conf/zoo.cfg << EOF
            server.1=$HOST_PRE-01.$S_DOMAIN.pd.infn.it:2888:3888
            server.2=$HOST_PRE-02.$S_DOMAIN.pd.infn.it:2888:3888
            server.3=$HOST_PRE-03.$S_DOMAIN.pd.infn.it:2888:3888
            EOF
            systemctl enable zookeeper-server
            cat >> /etc/bashrc << EOF
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export JRE_HOME=/usr/lib/jvm/jre-1.8.0-openjdk/jre
            EOF
            cat >> /etc/sysctl.conf << EOF
            net.ipv6.conf.all.disable_ipv6 = 1
            net.ipv6.conf.default.disable_ipv6 = 1
            EOF
            chmod 777 /opt/
            useradd hadoop
            echo -n hadoop:$HADOOP_PW | chpasswd
            source /etc/bashrc
            wget -O /tmp/hadoop-$HDOOP_V.tar.gz http://www.eu.apache.org/dist/hadoop/common/hadoop-$HDOOP_V/hadoop-$HDOOP_V.tar.gz
            tar -C /opt -zxf /tmp/hadoop-$HDOOP_V.tar.gz
            mv /opt/hadoop-$HDOOP_V /opt/hadoop
            chown -R hadoop.hadoop /opt/hadoop
            cat >> /home/hadoop/.bashrc << EOF
            export HADOOP_PREFIX=/opt/hadoop
            export HADOOP_HOME=\$HADOOP_PREFIX
            export HADOOP_COMMON_HOME=\$HADOOP_PREFIX
            export HADOOP_CONF_DIR=\$HADOOP_PREFIX/etc/hadoop
            export HADOOP_HDFS_HOME=\$HADOOP_PREFIX
            export HADOOP_MAPRED_HOME=\$HADOOP_PREFIX
            export HADOOP_YARN_HOME=\$HADOOP_PREFIX
            export PATH=$PATH:\$HADOOP_PREFIX/sbin:\$HADOOP_PREFIX/bin
            EOF
            #
            # https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/
            #
            mkdir /home/hadoop/datanode /home/hadoop/namenode
            chown hadoop.hadoop /home/hadoop/datanode /home/hadoop/namenode
            cat > /opt/hadoop/etc/hadoop/core-site.xml << EOF
            <configuration>
              <property>
                <name>fs.defaultFS</name>
                <value>hdfs://$HOST_PRE-01.$S_DOMAIN.pd.infn.it:9000/</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/hdfs-site.xml << EOF
            <configuration>
              <property>
                <name>dfs.replication</name>
                <value>1</value>
              </property>
              <property>
                <name>dfs.permissions</name>
                <value>false</value>
              </property>
              <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/hadoop/datanode</value>
              </property>
              <property>
                <name>dfs.namenode.name.dir</name>
                <value>/home/hadoop/namenode</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/mapred-site.xml << EOF
            <configuration>
              <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/yarn-site.xml << EOF
            <configuration>
              <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.hostname</name>
                <value>$HOST_PRE-01</value>
              </property>
              <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
              </property>
            </configuration>
            EOF
            cat > /opt/hadoop/etc/hadoop/slaves << EOF
            $HOST_PRE-02
            $HOST_PRE-03
            EOF
          params:
            $IP_FIX_NODE1: { get_param: fixed_ip_node_1 }
            $IP_FIX_NODE2: { get_param: fixed_ip_node_2 }
            $IP_FIX_NODE3: { get_param: fixed_ip_node_3 }
            $IP_NS1: { get_param: nameserver_1 }
            $IP_NS2: { get_param: nameserver_2 }
            $HOST_NUMBER: "3"
            $ROOT_PW: {get_resource: root_pw}
            $HADOOP_PW: {get_resource: hadoop_pw}
            $HOST_PRE: { get_param: net_host_prefix }
            $S_DOMAIN: { get_param: net_domain }
            $HDOOP_V: { get_param: hadoop_ver }



outputs:
  root_pw:
    description: root pwd to access to all VMs in mesos cluster
    value: {get_resource: root_pw}

  hadoop_pw:
    description: hadoop pwd to access to all VMs in hadoop cluster
    value: {get_resource: hadoop_pw}
